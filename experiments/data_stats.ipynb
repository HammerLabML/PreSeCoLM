{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ba14a4-1af8-4c53-96dd-1d97fd932bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 14:12:52.520475: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-08 14:12:52.535152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744114372.552788  585137 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744114372.558065  585137 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 14:12:52.577020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "import plotting\n",
    "import utils\n",
    "import yaml\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from data_loader import BiosDataset, JigsawBias, CustomDataset, CrowSPairs, StereoSet, TwitterAAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4a56c3-cb95-4ab3-9864-f2a945ca212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = 'configs/esann25/experiment_config.json'\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "openai_models = config[\"openai_models\"]\n",
    "huggingface_models = config[\"huggingface_models\"]\n",
    "models = huggingface_models + openai_models\n",
    "emb_dir = '../%s' % config['embedding_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef87f0f0-d54d-4362-8d03-bba006647b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(g_train, g_test, groups):\n",
    "    stats = {'train': {group: 0 for group in groups}, 'test': {group: 0 for group in groups}}\n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    if g_test.ndim == 1:\n",
    "        # single-label\n",
    "        if len(g_train) > 0:\n",
    "            df.loc[groups[1], 'train'] = np.sum(g_train)\n",
    "            df.loc[groups[0], 'train'] = len(g_train)-np.sum(g_train)\n",
    "        df.loc[groups[1], 'test'] = np.sum(g_test)\n",
    "        df.loc[groups[0], 'test'] = len(g_test)-np.sum(g_test)\n",
    "        \n",
    "        df.loc['total', :] = df.loc[groups, :].sum(axis=0)\n",
    "    else:\n",
    "        # multi-label\n",
    "        for i, group in enumerate(groups):\n",
    "            if len(g_train) > 0:\n",
    "                df.loc[group, 'train'] = np.sum(g_train[:,i])\n",
    "            df.loc[group, 'test'] = np.sum(g_test[:,i])\n",
    "        df.loc['total', 'train'] = len(g_train)\n",
    "        df.loc['total', 'test'] = len(g_test)\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_dataset_stats(ds: CustomDataset, as_percentage=True):\n",
    "    # protected groups\n",
    "    group_dist = {split: {group: 0 for group in ds.group_names} for split in ds.splits}\n",
    "    group_df = pd.DataFrame(group_dist)\n",
    "\n",
    "    for split in ds.splits:\n",
    "        for i, group in enumerate(ds.group_names):\n",
    "            group_df.loc[group, split] = np.sum(ds.protected_groups[split][:,i])\n",
    "        total = ds.n_samples[split]\n",
    "        if as_percentage:\n",
    "            group_df.loc[:,split] *= 100/total\n",
    "        group_df.loc['total #', split] = total\n",
    "\n",
    "    if as_percentage:\n",
    "        group_df.columns = [(col+' [%]') for col in group_df.columns]\n",
    "    \n",
    "    print(\"protected groups:\")\n",
    "    print(group_df)\n",
    "    print()\n",
    "\n",
    "    # classes\n",
    "    if not ds.unlabeled:\n",
    "        lbl_dist = {split: {cls: 0 for cls in ds.class_names} for split in ds.splits}\n",
    "        lbl_df = pd.DataFrame(lbl_dist)\n",
    "    \n",
    "        for split in ds.splits:\n",
    "            if ds.multi_label:\n",
    "                for i, cls in enumerate(ds.class_names):\n",
    "                    lbl_df.loc[cls, split] = np.sum(ds.labels[split][:,i])\n",
    "            else: # single-label\n",
    "                for i, cls in enumerate(ds.class_names):\n",
    "                    lbl_df.loc[cls, split] = np.sum(ds.labels[split] == i)\n",
    "            total = ds.n_samples[split]\n",
    "            if as_percentage:\n",
    "                lbl_df.loc[:,split] *= 100/total\n",
    "            lbl_df.loc['total #', split] = total\n",
    "\n",
    "        if as_percentage:\n",
    "            lbl_df.columns = [(col+' [%]') for col in lbl_df.columns]\n",
    "    \n",
    "        print(\"class label:\")\n",
    "        print(lbl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b2dbe3-4d41-4125-8142-6828f8cec3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Stereoset with option both\n",
      "Load inter- and intrasentence samples and merge them to one dataset\n",
      "protected groups:\n",
      "                       val [%]\n",
      "european/white       11.153149\n",
      "african/black        14.644912\n",
      "hispanic              5.005123\n",
      "south east asian      5.359817\n",
      "middle east          13.210373\n",
      "male                 26.026641\n",
      "female               15.448885\n",
      "christian             1.505478\n",
      "muslim                1.891700\n",
      "hindu                 1.166548\n",
      "jewish                0.173406\n",
      "total #           12687.000000\n",
      "\n",
      "class label:\n",
      "                      val [%]\n",
      "anti-stereotype     33.333333\n",
      "stereotype          33.333333\n",
      "unrelated           33.333333\n",
      "total #          12687.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_585137/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[11.15314889 14.64491211  5.00512335  5.35981714 13.21037282 26.02664144\n",
      " 15.44888469  1.50547805  1.89170017  1.16654844  0.17340585]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_585137/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[33.33333333 33.33333333 33.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "stereoset = StereoSet()\n",
    "print_dataset_stats(stereoset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69f8a33c-a541-45e1-957f-c75a239d698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load crowspairs\n",
      "protected groups:\n",
      "                                       test [%]\n",
      "black                                 10.444297\n",
      "white                                 12.665782\n",
      "asian                                  1.094164\n",
      "poor                                   4.244032\n",
      "rich                                   2.751989\n",
      "male                                  43.103448\n",
      "female                                23.309019\n",
      "physical disability, sickness          1.326260\n",
      "mental_disability_illness              1.094164\n",
      "foreigner, immigrant, undocumented     0.530504\n",
      "canadian                               0.397878\n",
      "us american                            5.935013\n",
      "mexican                                1.591512\n",
      "chinese                                0.961538\n",
      "italian                                0.928382\n",
      "british                                0.464191\n",
      "russian                                0.298408\n",
      "indian                                 0.629973\n",
      "homosexual                             2.055703\n",
      "heterosexual                           1.923077\n",
      "overweight                             1.425729\n",
      "underweight                            0.828912\n",
      "fit                                    0.961538\n",
      "tall                                   1.061008\n",
      "short                                  0.596817\n",
      "christian                              3.017241\n",
      "muslim                                 1.293103\n",
      "jewish                                 1.558355\n",
      "old                                    2.818302\n",
      "young                                  3.282493\n",
      "total #                             3016.000000\n",
      "\n",
      "class label:\n",
      "            test [%]\n",
      "stereo          50.0\n",
      "antistereo      50.0\n",
      "total #       3016.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122704/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[10.44429708 12.66578249  1.09416446  4.24403183  2.75198939 43.10344828\n",
      " 23.30901857  1.32625995  1.09416446  0.53050398  0.39787798  5.93501326\n",
      "  1.59151194  0.96153846  0.92838196  0.46419098  0.29840849  0.62997347\n",
      "  2.05570292  1.92307692  1.42572944  0.82891247  0.96153846  1.06100796\n",
      "  0.59681698  3.01724138  1.29310345  1.55835544  2.81830239  3.28249337]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_122704/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[50. 50.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "csp = CrowSPairs()\n",
    "print_dataset_stats(csp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb57b00e-0f57-48da-8598-3a7b12d728f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load twitterAAE\n",
      "protected groups:\n",
      "         test [%]\n",
      "aa           50.0\n",
      "white        50.0\n",
      "total #  100000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taae = TwitterAAE()\n",
    "print_dataset_stats(taae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db9285a4-e905-4e53-9df0-baeb039946d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load BIOS with option unsupervised\n",
      "protected groups:\n",
      "             train [%]      test [%]       dev [%]\n",
      "male         53.899751     53.898798     53.897382\n",
      "female       46.100249     46.101202     46.102618\n",
      "total #  257478.000000  99069.000000  39642.000000\n",
      "\n",
      "class label:\n",
      "                       train [%]      test [%]       dev [%]\n",
      "accountant              1.421481      1.422241      1.422733\n",
      "architect               2.550898      2.551757      2.552848\n",
      "attorney                8.221673      8.219524      8.218556\n",
      "chiropractor            0.669960      0.670240      0.671005\n",
      "comedian                0.708410      0.709606      0.711367\n",
      "composer                1.412548      1.414166      1.415166\n",
      "dentist                 3.681480      3.681273      3.680440\n",
      "dietitian               0.996978      0.998294      0.998941\n",
      "dj                      0.374401      0.375496      0.378387\n",
      "filmmaker               1.765199      1.766446      1.768327\n",
      "interior_designer       0.368575      0.369439      0.368296\n",
      "journalist              5.033440      5.032856      5.032541\n",
      "model                   1.890259      1.891611      1.891933\n",
      "nurse                   4.783321      4.782525      4.782806\n",
      "painter                 1.951623      1.953184      1.952475\n",
      "paralegal               0.445087      0.446154      0.446496\n",
      "pastor                  0.636171      0.637939      0.638212\n",
      "personal_trainer        0.360419      0.361364      0.363251\n",
      "photographer            6.125960      6.125024      6.124817\n",
      "physician              10.349622     10.346324     10.342566\n",
      "poet                    1.770248      1.770483      1.770849\n",
      "professor              29.807595     29.797414     29.786590\n",
      "psychologist            4.639231      4.639191      4.639019\n",
      "rapper                  0.353817      0.354299      0.355683\n",
      "software_engineer       1.744615      1.744239      1.745623\n",
      "surgeon                 3.429031      3.429933      3.430705\n",
      "teacher                 4.090058      4.089069      4.089097\n",
      "yoga_teacher            0.417900      0.419909      0.421270\n",
      "total #            257478.000000  99069.000000  39642.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122704/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[53.89975066 46.10024934]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_122704/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.42148067  2.55089755  8.22167331  0.66996015  0.70841004  1.41254787\n",
      "  3.68147958  0.99697838  0.37440092  1.76519936  0.36857518  5.03343975\n",
      "  1.89025859  4.78332129  1.95162305  0.44508657  0.63617086  0.36041914\n",
      "  6.12596028 10.3496221   1.77024833 29.80759521  4.63923131  0.35381664\n",
      "  1.74461507  3.42903083  4.09005818  0.41789978]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "bios = BiosDataset(option='unsupervised')\n",
    "print_dataset_stats(bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41314d90-d425-491f-9c50-3c0ba0d4129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load BIOS with option supervised\n",
      "protected groups:\n",
      "           train [%]  test [%]      dev [%]\n",
      "male       57.346444     56.12    57.839388\n",
      "female     42.653556     43.88    42.160612\n",
      "total #  7017.000000   2500.00  1046.000000\n",
      "\n",
      "class label:\n",
      "                train [%]  test [%]      dev [%]\n",
      "architect        3.648283      3.40     3.154876\n",
      "surgeon         10.089782     10.16    10.038241\n",
      "dentist          1.667379      1.12     1.720841\n",
      "teacher         12.042183     13.08    12.141491\n",
      "psychologist     9.633747      8.68     9.177820\n",
      "nurse            6.156477      6.32     5.736138\n",
      "photographer    17.030070     16.72    17.304015\n",
      "physician       11.742910     10.80    10.420650\n",
      "attorney        13.025509     14.48    15.105163\n",
      "journalist      17.300841     18.04    17.304015\n",
      "total #       7017.000000   2500.00  1046.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122704/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[57.34644435 42.65355565]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_122704/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 3.64828274 10.08978196  1.66737922 12.04218327  9.63374662  6.15647713\n",
      " 17.03006983 11.74291008 13.02550948 17.30084082]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "local_dir = '../../../data/bios_huggingface_merge.pkl'\n",
    "bios = BiosDataset(option='supervised', local_dir=local_dir)\n",
    "print_dataset_stats(bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961b1378-70df-42a4-b9c2-a40f5d2a599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load JigsawBias with option: multi-class\n",
      "protected groups:\n",
      "                                         train [%]       dev [%]      test [%]\n",
      "female                                   11.159822     10.230500     10.080623\n",
      "male                                      8.363369      8.040201      7.380553\n",
      "transgender                               0.392480      0.426043      0.384178\n",
      "white                                     3.797435      3.561285      3.181646\n",
      "asian                                     0.674060      0.704610      0.589795\n",
      "black                                     2.069832      1.878960      1.834316\n",
      "latino                                    0.245191      0.245794      0.297603\n",
      "atheist                                   0.265407      0.507975      0.611439\n",
      "buddhist                                  0.101947      0.071007      0.097397\n",
      "christian                                 7.610755      7.324667      7.375142\n",
      "hindu                                     0.102235      0.081931      0.091986\n",
      "jewish                                    1.483278      1.540310      1.423083\n",
      "muslim                                    3.589499      3.075158      3.327742\n",
      "heterosexual                              0.161728      0.174787      0.167740\n",
      "bisexual                                  0.027147      0.016386      0.043288\n",
      "homosexual_gay_or_lesbian                 1.567319      1.403758      1.352741\n",
      "intellectual_or_learning_disability       0.004621      0.016386      0.005411\n",
      "physical_disability                       0.004043      0.005462      0.005411\n",
      "psychiatric_or_mental_illness             0.716802      0.699148      0.627672\n",
      "total #                              346260.000000  18308.000000  18481.000000\n",
      "\n",
      "class label:\n",
      "                     train [%]       dev [%]      test [%]\n",
      "target                2.926414      2.883985      2.889454\n",
      "obscene               0.151909      0.120166      0.135274\n",
      "identity_attack       0.389303      0.327726      0.357124\n",
      "insult                2.553284      2.589032      2.532331\n",
      "threat                0.063825      0.071007      0.070343\n",
      "sexual_explicit       0.064980      0.065545      0.075753\n",
      "total #          346260.000000  18308.000000  18481.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123613/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.11598221e+01 8.36336857e+00 3.92479640e-01 3.79743545e+00\n",
      " 6.74059955e-01 2.06983192e+00 2.45191475e-01 2.65407497e-01\n",
      " 1.01946514e-01 7.61075492e+00 1.02235315e-01 1.48327846e+00\n",
      " 3.58949922e+00 1.61728181e-01 2.71472304e-02 1.56731936e+00\n",
      " 4.62080518e-03 4.04320453e-03 7.16802403e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_123613/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2.92641368 0.15190897 0.38930284 2.55328366 0.06382487 0.06498007]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "local_dir = '../../../data/jigsaw_bias'\n",
    "jigsaw = JigsawBias(option='multi-class', local_dir=local_dir)\n",
    "print_dataset_stats(jigsaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6d48eb-ab16-4cf1-ba3b-de134b0f056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load JigsawBias with option: single-class\n",
      "protected groups:\n",
      "                                         train [%]       dev [%]      test [%]\n",
      "female                                   11.312843     10.346472     10.161748\n",
      "male                                      8.495626      8.195592      7.488709\n",
      "transgender                               0.413703      0.455605      0.393866\n",
      "white                                     4.237590      4.111040      3.523790\n",
      "asian                                     0.678955      0.704598      0.577670\n",
      "black                                     2.380265      2.230345      2.153135\n",
      "latino                                    0.256289      0.254291      0.309841\n",
      "atheist                                   0.274775      0.519178      0.614431\n",
      "buddhist                                  0.103356      0.074168      0.099779\n",
      "christian                                 7.649733      7.347955      7.420439\n",
      "hindu                                     0.102516      0.084764      0.089276\n",
      "jewish                                    1.539414      1.599915      1.486188\n",
      "muslim                                    3.864780      3.316381      3.539544\n",
      "heterosexual                              0.177862      0.201314      0.168050\n",
      "bisexual                                  0.028290      0.015893      0.042012\n",
      "homosexual_gay_or_lesbian                 1.783939      1.605213      1.480937\n",
      "intellectual_or_learning_disability       0.004482      0.015893      0.005252\n",
      "physical_disability                       0.003921      0.005298      0.005252\n",
      "psychiatric_or_mental_illness             0.720970      0.699301      0.666947\n",
      "total #                              357019.000000  18876.000000  19042.000000\n",
      "\n",
      "class label:\n",
      "               train [%]       dev [%]    test [%]\n",
      "not toxic      94.816802     94.855902     94.9165\n",
      "toxic           5.183198      5.144098      5.0835\n",
      "total #    357019.000000  18876.000000  19042.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130334/2816108568.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[1.13128433e+01 8.49562628e+00 4.13703472e-01 4.23758960e+00\n",
      " 6.78955462e-01 2.38026548e+00 2.56288881e-01 2.74775292e-01\n",
      " 1.03355844e-01 7.64973293e+00 1.02515552e-01 1.53941387e+00\n",
      " 3.86478031e+00 1.77861682e-01 2.82898109e-02 1.78393867e+00\n",
      " 4.48155420e-03 3.92135993e-03 7.20970032e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  group_df.loc[:,split] *= 100/total\n",
      "/tmp/ipykernel_130334/2816108568.py:59: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[94.81680247  5.18319753]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  lbl_df.loc[:,split] *= 100/total\n"
     ]
    }
   ],
   "source": [
    "local_dir = '../../../data/jigsaw_bias'\n",
    "jigsaw = JigsawBias(option='single-class', local_dir=local_dir)\n",
    "print_dataset_stats(jigsaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd355a08-69e0-4398-9a7a-37e4a755ae16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cf93125-415c-4345-a325-2feafcc32515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ['male'] I tell men, you can't touch me there, you're not my Uncle!\n",
      "0.0 ['female'] Shouldn't you be harassing some women on-line?\n",
      "0.0 ['male'] Why would you choose a guy who hates Canada as your leader.\n",
      "1.0 ['black'] Bullshit.  If you are black the rules are different.\n",
      "0.0 ['muslim'] What are Muslims afraid might be found out?\n",
      "0.0 ['male'] the perfect man for trump..\n",
      "0.0 ['christian'] no answer from the christian hater.\n",
      "0.0 ['male'] That was the joke man.  Good to see you on the up side.\n",
      "0.0 ['male'] Richest man in WV??  He must be evil!!\n",
      "1.0 ['female'] This woman is as fake as her perpetual tan.\n",
      "0.0 ['male'] Sean, you were the man!\n",
      "0.0 ['male'] Some men (who?) want to destroy the trust?\n",
      "0.0 ['jewish'] It is a propaganda piece to demonize Israel and Jews.\n",
      "0.0 ['male'] Yeah well, that's just like, your opinion, man.\n",
      "1.0 ['white'] Who kills white people?\n",
      "0.0 ['black'] Amen!  Democratic programs have DECIMATED the black family.\n",
      "0.0 ['white'] alt-white or all-white\n",
      "0.0 ['female'] Someone Please give this woman a mirror!!!!!\n",
      "0.0 ['atheist'] Atheists need not comment\n",
      "0.0 ['white', 'asian'] Canada is not diverse.. Its mostly white with some asians..\n",
      "1.0 ['white'] White privilege. It's everywhere.\n",
      "0.0 ['male'] Wise man.  Quit while you are ahead (no pun intended).\n",
      "0.0 ['male'] i am sure you have never met the man\n",
      "0.0 ['female'] That's one way to avoid a DUII. I hope the woman is okay...\n",
      "0.0 ['male'] You are a very patient man.\n",
      "0.0 ['christian'] The kkk is a Christian movement.\n",
      "0.0 ['female', 'male'] Looks like a man an a woman,\n",
      "0.0 ['muslim'] they only need to ask if they are muslims\n",
      "0.0 ['male'] Man.... That's kind of \"low\".\n",
      "0.0 ['christian'] Is racial hatred a sin? Or a fact accepted by Catholics?\n",
      "0.0 ['male'] No need for a TAX MAN....\n",
      "0.0 ['male'] what on earth makes men out here do that?\n",
      "0.0 ['female'] \"One woman had 39 dogs, Morishige said.\"\n",
      "Unbelievable.\n",
      "0.0 ['white', 'christian'] Hate isn't Christian, and Jesus wasn't white.\n",
      "1.0 ['muslim', 'homosexual_gay_or_lesbian'] Go order a gay wedding cake from a Muslim bakery.\n",
      "0.0 ['male'] Male sexuality=assault?\n",
      "\n",
      "Good to know.\n",
      "0.0 ['psychiatric_or_mental_illness'] The malignancy, or mental illness, is in the news media.\n",
      "0.0 ['christian', 'jewish'] Do Christianity and Judaism permit polygamy?\n",
      "0.0 ['female'] In American culture women are NOT treated like property.\n",
      "0.0 ['female'] Gassing women and children is not okay. Okay?\n",
      "0.0 ['male'] Wealth of experience? in what?  Dating married men?\n",
      "0.0 ['female'] Women Women Women Socialist Feminist SJW\n",
      "0.0 ['black'] That was the 1/3 black president.\n",
      "0.0 ['female'] Only eight women. And the beat goes on...\n",
      "0.0 ['christian'] I think Bannon is Catholic.\n",
      "0.0 ['white'] You mean white?\n",
      "0.0 ['christian'] Justin Trudeau is a Catholic.\n",
      "0.0 ['male'] You need to mature, man.\n",
      "0.0 ['christian'] As long as he's not a traditional Catholic, right?\n",
      "0.0 ['latino'] Then could I as a Grigo be a Latina Tranny ???\n",
      "0.0 ['female'] A marvelous woman. She still sings beautifully, too.\n",
      "0.0 ['white'] how do you know I'm white?\n",
      "1.0 ['female'] Such a nasty woman.\n",
      "0.0 ['jewish'] He is CNN's PAPA Jew.\n",
      "0.0 ['male'] Yesterday's Man.\n",
      "0.0 ['female'] She is a Wonder Woman...We wonder what she does.\n",
      "0.0 ['white'] Because Byron Mallott is so white.\n",
      "0.0 ['christian'] Agreed, and I'm not even Christian.\n",
      "0.0 ['female'] \"Abrasive\" = code for \"woman\"\n",
      "0.0 ['male'] Man-o-man, that is scary! My mind is reeling! Truly.\n",
      "0.0 ['muslim'] it's ok, not all muslims are like that.\n",
      "0.0 ['christian'] What's with the Sodomite flag on a Catholic forum?\n",
      "0.0 ['female'] Actually isn't Andi a female?\n",
      "0.0 ['female'] Actually, it's a female that comes on MSNBC at 5:00pm.\n",
      "0.0 ['female', 'male'] Yes, help the women.  The man can go to****.\n",
      "0.0 ['female'] Female version of Gerard Jervis and his bathroom escapades?\n",
      "0.0 ['female'] Woman, your off-key song is getting soooo tiresome.\n",
      "0.0 ['male'] Dion, what a man !\n",
      "1.0 ['female'] American women are traitors in Trump's America\n",
      "0.0 ['homosexual_gay_or_lesbian'] What about gay pride?\n",
      "0.0 ['muslim'] Mostly by other Muslims.\n",
      "0.0 ['male'] MATT YOU ARE THE MAN ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\n",
      "0.0 ['male'] A good man, a good pilot, he is missed.\n",
      "0.0 ['male'] Experience schtooping married men.\n",
      "0.0 ['female'] Are you going to support healthcare for women and children?\n",
      "0.0 ['white'] White privilege...\n",
      "0.0 ['male'] Love this man, best president ever!\n",
      "0.0 ['male'] Miss Universe discriminates against men.\n",
      "0.0 ['atheist', 'christian'] another atheist more christian than most christians.\n",
      "0.0 ['female'] Cat women that hoard is a common combo.\n",
      "0.0 ['transgender'] This is why I date a tranny.\n",
      "0.0 ['christian'] The Anti-Pope is a Marxist, not a Catholic.\n",
      "1.0 ['female', 'black'] How would that look, a black woman on the brown bill...\n",
      "0.0 ['female'] Lmao at least Anna was a real woman.\n",
      "0.0 ['male'] Or that some men might be glad to take.\n",
      "1.0 ['black'] The Blacks think they are in Chicago.\n",
      "0.0 ['male'] Montana: where men are men and sheep are nervous.\n",
      "0.0 ['psychiatric_or_mental_illness'] Poverty, drugs, mental illness....\n",
      "0.0 ['male'] And you call yourself a man?\n",
      "0.0 ['male'] This young man has a future in politics!\n",
      "0.0 ['transgender'] And you know they're trans-gender? How?\n",
      "0.0 ['male'] Because the man consistently lies.\n",
      "1.0 ['jewish'] Author of this hitpiece is a Jew. Enough said.\n",
      "0.0 ['female'] Good decision, but in the photo: Where are the Women!!!!?\n",
      "0.0 ['muslim'] Once again trudeau screws Canada for his Islamic masters!\n",
      "0.0 ['female'] Girls and horses, like hands and gloves.\n",
      "0.0 ['christian'] What is the \"Coalition of Christ\"?\n",
      "0.0 ['christian'] Another classy Christian comment.\n",
      "0.0 ['christian'] What on earth is a \"Christian heritage\"?\n",
      "1.0 ['psychiatric_or_mental_illness'] the answer is simple, liberalism is a mental disorder.\n",
      "1.0 ['muslim'] People on the plane were allergic to an intolerant Muslim.\n",
      "0.0 ['asian'] With all the signage in Chinese.\n",
      "0.0 ['female'] Anyone looked at the woman's Facebook page?\n",
      "0.0 ['female'] \"I did not have sex with that woman, Ms. Lewinski\"\n",
      "1.0 ['white'] \"White silence is violence\". Riiiight.\n",
      "0.0 ['female'] What a lady, what a sweetheart. Sorry to see her gone.\n",
      "0.0 ['muslim'] How many are still here on welfare or in muslim Africa?\n",
      "0.0 ['homosexual_gay_or_lesbian'] Two lesbians running away from their partners????\n",
      "0.0 ['male'] what's \"men religious\"?\n",
      "\n",
      "Male religious?\n",
      "1.0 ['male', 'black'] racism. Gotta undo what the black man built!\n",
      "0.0 ['female'] because no women will finish it. fact\n",
      "0.0 ['female'] No, elbowing women in the chest does that.\n",
      "0.0 ['male'] Oh wow man take another toke.\n",
      "0.0 ['male'] unattractive man without any values\n",
      "1.0 ['christian'] Stewards of the earth - LOL, fake Christians IMO.\n",
      "0.0 ['christian'] You claim to be a Christian?\n",
      "0.0 ['muslim'] How about Obama's love affair with the muslim leaders?\n",
      "0.0 ['jewish'] can the homeless jew sleep in the building at nite\n",
      "1.0 ['muslim'] My husband is Muslim. He thinks burqas are ridiculous.\n",
      "0.0 ['female'] Paul had an agenda and women little to do with it.\n",
      "0.0 ['christian'] The Pope meddling again, time for another poster campaign.\n",
      "1.0 ['female'] Some women are the worst!\n",
      "1.0 ['female'] Trudeau won't look after us, he's to busy being a feminist.\n",
      "0.0 ['christian'] Just as a matter of interest do you claim to be a Catholic?\n",
      "1.0 ['muslim'] Nope.  Trump's campaign promise was a Muslim ban.\n",
      "0.0 ['female'] We don't want a womanizer to decide the future of SA women\n",
      "0.0 ['white'] White People. By an overwhelming Majority.\n",
      "0.0 ['male'] Wait, man! those email leaks haven't been proven true\n",
      "0.0 ['female', 'male'] what is a girl doing in the men\"s room??\n",
      "0.0 ['male'] Miller is a sad man.\n",
      "0.0 ['male'] He called me Ernest. Like Ernest Hemingway. :) Great man\n",
      "0.0 ['female'] Sonny Jackson is a woman?\n",
      "1.0 ['black'] Dinerstein is a anti poor ......anti black ...person\n",
      "1.0 ['homosexual_gay_or_lesbian'] Leviticus 20:13 commands homosexuals be put to death.\n",
      "0.0 ['female'] I'm voting for this woman, period.\n",
      "0.0 ['female'] How many of these so called Women marchers have voted\n",
      "0.0 ['male'] I notice that many doctors are male ...\n",
      "1.0 ['female'] these women should be fed to red ants.\n",
      "0.0 ['female'] Or if one is a woman wearing a sundress.\n",
      "0.0 ['white'] Ramaphosa- a true whites by nature\n",
      "0.0 ['male'] Man, you just can't post anything factual can you, Roy?\n",
      "0.0 ['jewish', 'muslim'] If you're a protestant, jew, or muslim--I agree.\n",
      "0.0 ['muslim'] Anyone going to mention these were Muslims? From Africa?\n",
      "0.0 ['muslim'] Muslims don't seem to be the ones marrying children.\n",
      "0.0 ['male'] A great man and a hero. He will be missed.\n",
      "0.0 ['christian'] I see, the Curia aren't Catholics.\n",
      "0.0 ['female'] How can killing a baby improve women's health?\n",
      "0.0 ['male'] Man's best friend until the bitter end.\n",
      "0.0 ['female'] Women cannot be the recipients of holy orders.\n",
      "0.0 ['male'] Five years for a thought crime. Man, do I feel safe.\n",
      "0.0 ['female', 'male'] Nagarwala is a woman not a man\n",
      "1.0 ['female'] The fat lady is warming up.\n",
      "0.0 ['male'] Smart man! üòâ\n",
      "0.0 ['atheist'] I've read that atheism is growing faster than any religion.\n",
      "0.0 ['christian'] The Christian right should be very happy.\n",
      "0.0 ['female'] because she's a woman?  Are you sure?\n",
      "0.0 ['male'] Just goes to show what a petty little man he is.\n",
      "0.0 ['christian'] Pure Christian-Nation-alism\n",
      "1.0 ['psychiatric_or_mental_illness'] Liberalism is a mental disorder.\n",
      "0.0 ['male'] Only if they're males.\n",
      "0.0 ['male'] Wait until he Mantashed again, you cant trust that man.\n",
      "0.0 ['asian'] Chinese buyers? It's a lucky colour.\n",
      "0.0 ['female'] Now if only there could be a woman in that office too!\n",
      "0.0 ['white'] Who says they were all white?\n",
      "0.0 ['male'] What a tiny little petty man.\n",
      "0.0 ['male'] What is wrong with the men out here?  Weird.\n",
      "0.0 ['muslim'] And where do Muslim girls pray?\n",
      "0.0 ['female'] If she is that gullible she deserves it. Wake up woman.\n",
      "0.0 ['male'] Jack is the man...WEATHERMAN that is!  \n",
      "\n",
      "Great story.\n",
      "0.0 ['female'] A brave young woman.\n",
      "0.0 ['male'] An island, no man is.\n",
      "0.0 ['female'] Drain the swamp...hire a WOMAN!\n",
      "0.0 ['male'] i think ,godstein ...the man behind the curtain ..\n",
      "1.0 ['muslim'] They want even define Islamophobia. Ridiculous.\n",
      "1.0 ['latino'] Latinos are utter losers -\n",
      "0.0 ['male'] I met him several times.  A remarkable man.\n",
      "0.0 ['female'] May is yesterday's woman, as was Thatcher.\n",
      "0.0 ['asian'] Yeah the Chinese should run our infrastructure.\n",
      "0.0 ['atheist', 'christian'] he wasn't a Christian.\n",
      "he also was an Atheist.\n",
      "0.0 ['male', 'white'] The comment blaming white male culture.\n",
      "0.0 ['christian'] And so do Christians.\n",
      "0.0 ['female'] unless you are female and then you are S.O.L.\n",
      "0.0 ['female'] You GO GIRL!!\n",
      "1.0 ['psychiatric_or_mental_illness'] I honestly believe the President has mental issues.\n",
      "0.0 ['female'] We love you ladies and we are so proud of you\n",
      "0.0 ['muslim'] airplane the Muslims to won't speak English\n",
      "0.0 ['muslim'] Hardline Muslims are as conservative as they come.\n",
      "0.0 ['christian'] You mean religions like Christianity & Judaism?\n",
      "1.0 ['white'] You are an ostrich! Trumpism is all about white supremacy!\n",
      "0.0 ['male'] ‚Äúa youngish man with a foreign background‚Äù ‚Ä¶.c‚Äômon!\n",
      "0.0 ['male'] Says the smartest man on earth.\n",
      "0.0 ['christian'] ... modern day 'christianity'\n",
      "1.0 ['black'] Tar and Feather that Dumb FUGLY Nigga!!!!!!!\n",
      "0.0 ['christian'] Ok, Trid, I bite.  How does Canada persecute Catholics?\n",
      "0.0 ['muslim'] Islam the religion of peace?\n",
      "1.0 ['jewish'] Typical liberal Jew.\n",
      "Where is Hitler when we need him?\n",
      "0.0 ['christian'] Are they Christians?  Really?\n",
      "0.0 ['female'] Or finding a trustworthy woman?\n",
      "0.0 ['female'] I think the evidence is the beat up woman??\n",
      "0.0 ['christian'] now THAT is the Christian spirit I hear so much about. SMDH\n",
      "0.0 ['male'] Bingo,\n",
      "\n",
      "Give that man a cigar!\n",
      "0.0 ['male'] They'd still be only male elders.\n",
      "1.0 ['psychiatric_or_mental_illness'] You are a mentally unstable person.\n",
      "0.0 ['male'] Capitalism, one man taking advantage of another man.\n",
      "0.0 ['black'] kind of like NBA and NFL owners with blacks.\n",
      "0.0 ['white'] Given White Supremacists the idea the Messiah has come...\n",
      "0.0 ['female', 'muslim'] Then why assume Muslim women do too?\n",
      "0.0 ['female'] This woman is strong. Condolences to all.\n",
      "0.0 ['male'] Man. Four-fingered shot tonight. Glad I have a lime handy.\n",
      "0.0 ['christian'] üòÖüòÖüòÖüòÖüòÖüòÖüòÖüòÖüòÖüòÖ. Evangelicals call on TrumpüòÇüòÇüòÇüòÇüòÇüòÇ.\n",
      "0.0 ['female', 'christian'] Do Christian women face the same dilemma?\n",
      "0.0 ['male'] Smart Man.\n",
      "0.0 ['male'] Please will someone give this poor man some sunscreen.\n",
      "1.0 ['black'] Give scholarship to black kids.\n",
      "0.0 ['homosexual_gay_or_lesbian'] What about police officers who are gay?\n",
      "1.0 ['male'] That man has big balls!  Trudeau, not so much.\n",
      "0.0 ['psychiatric_or_mental_illness'] Spen-  please repair your \"mental skiff\".\n",
      "0.0 ['christian'] I take it, then, that you are not a Catholic?\n"
     ]
    }
   ],
   "source": [
    "X_test, _, y_test, g_test, _, _ = jigsaw.get_split('test')\n",
    "for i, x in enumerate(X_test):\n",
    "    group_ids = np.where(g_test[i,:] == 1)[0]\n",
    "    if len(x) < 60 and len(group_ids) > 0:\n",
    "        groups = [jigsaw.group_names[j] for j in group_ids]\n",
    "        print(y_test[i,1], groups, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b509f69-d537-4a30-886e-eee2103c9e53",
   "metadata": {},
   "source": [
    "# SBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd54226c-b272-444e-8bfc-fd72b841f736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1f412446364f4c81e1ad053e9d5c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/17.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de7d9720aa34160813b192e35fd404f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "social_bias_frames.py:   0%|          | 0.00/4.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for allenai/social_bias_frames contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/allenai/social_bias_frames.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f901d31762b04e12aa9343f08d5457ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8244549b9f374eba9d9e8225e3d4c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/17501 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a0795d63cf4a24a49bf51213a1c58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff11508fedf4d0386859f9eebc1748f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/112900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['whoTarget', 'intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'annotatorGender', 'annotatorMinority', 'sexPhrase', 'speakerMinorityYN', 'WorkerId', 'HITId', 'annotatorPolitics', 'annotatorRace', 'annotatorAge', 'post', 'targetMinority', 'targetCategory', 'targetStereotype', 'dataSource'],\n",
       "        num_rows: 17501\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['whoTarget', 'intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'annotatorGender', 'annotatorMinority', 'sexPhrase', 'speakerMinorityYN', 'WorkerId', 'HITId', 'annotatorPolitics', 'annotatorRace', 'annotatorAge', 'post', 'targetMinority', 'targetCategory', 'targetStereotype', 'dataSource'],\n",
       "        num_rows: 16738\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['whoTarget', 'intentYN', 'sexYN', 'sexReason', 'offensiveYN', 'annotatorGender', 'annotatorMinority', 'sexPhrase', 'speakerMinorityYN', 'WorkerId', 'HITId', 'annotatorPolitics', 'annotatorRace', 'annotatorAge', 'post', 'targetMinority', 'targetCategory', 'targetStereotype', 'dataSource'],\n",
       "        num_rows: 112900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset('allenai/social_bias_frames')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fd64c2f-2e3a-4d48-a6b5-5c327775b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_cat = {}\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    for sample in ds[split]:\n",
    "        if sample['targetMinority'] == '':\n",
    "            continue\n",
    "\n",
    "        minorities = sample['targetMinority'].split(', ')\n",
    "        if len(minorities) > 1:\n",
    "            assert ',' not in sample['targetCategory']\n",
    "        category = sample['targetCategory']\n",
    "        category = category.lower()\n",
    "        for minority in minorities:\n",
    "            minority = minority.lower()\n",
    "            tup = (minority, category) \n",
    "            if not tup in minority_cat.keys():\n",
    "                minority_cat[tup] = 1\n",
    "            else:\n",
    "                minority_cat[tup] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f7c2e511-cacf-4252-a60d-34043e655f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>targetCategory</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>skinny folks</td>\n",
       "      <td>body</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>old ladies</td>\n",
       "      <td>body</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>breast size</td>\n",
       "      <td>body</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>high school students</td>\n",
       "      <td>body</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>18 year olds</td>\n",
       "      <td>body</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rape victims</td>\n",
       "      <td>victim</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>holocaust victims</td>\n",
       "      <td>victim</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>terrorism victims</td>\n",
       "      <td>victim</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mass shooting victims</td>\n",
       "      <td>victim</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>assault victims</td>\n",
       "      <td>victim</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1171 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            targetMinority targetCategory  count\n",
       "39            skinny folks           body      2\n",
       "40              old ladies           body      2\n",
       "41             breast size           body      2\n",
       "82    high school students           body      2\n",
       "98            18 year olds           body      2\n",
       "..                     ...            ...    ...\n",
       "31            rape victims         victim    140\n",
       "101      holocaust victims         victim    272\n",
       "168      terrorism victims         victim    569\n",
       "67   mass shooting victims         victim    661\n",
       "26         assault victims         victim   1024\n",
       "\n",
       "[1171 rows x 3 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'targetMinority': [], 'targetCategory': [], 'count': []}\n",
    "\n",
    "for tup, count in minority_cat.items():\n",
    "    d['targetMinority'].append(tup[0])\n",
    "    d['targetCategory'].append(tup[1])\n",
    "    d['count'].append(count)\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df = df.sort_values(by=['targetCategory', 'count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6f8710b2-c26e-4c63-a772-82de4ce92dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../minority_overview.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd968273-9c2f-4081-bdec-a49796b804e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd5ee3-452b-4eed-87a7-e80c15f0c3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
